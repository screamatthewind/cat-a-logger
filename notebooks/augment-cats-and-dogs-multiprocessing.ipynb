{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a component of a larger project [Cat-A-Logger](https://github.com/screamatthewind/cat-a-logger) on github   \n",
    "See this [Short Slide Presentation](https://github.com/screamatthewind/cat-a-logger/blob/main/Slide%20Presentation%20-%20Short.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are we running locally or in kaggle?\n",
    "\n",
    "import os\n",
    "\n",
    "if os.environ.get('KAGGLE_KERNEL_RUN_TYPE','') == '':\n",
    "    print(\"We are running code on Localhost\")\n",
    "    isLocalhost = True\n",
    "\n",
    "else:\n",
    "    print(\"We are running in Kaggle\")\n",
    "    isLocalhost = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isLocalhost:\n",
    "    INPUT_FILES = './output/cropped-cats-and-dogs/*.jpg'\n",
    "    \n",
    "else:\n",
    "    INPUT_FILES = '/kaggle/input/cropped-cats-and-dogs/*.jpg'\n",
    "\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "\n",
    "    USER_ID = user_secrets.get_secret(\"user-id\")\n",
    "    API_TOKEN = user_secrets.get_secret(\"api-token\")\n",
    "    \n",
    "OUTPUT_DATASET_ID = 'augmented-cats-and-dogs'\n",
    "OUTPUT_DATASET_NAME = 'Augmented Cats and Dogs'\n",
    "OUTPUT_PATH = './output/augmented-cats-and-dogs'\n",
    "\n",
    "NUM_AUGMENTATIONS = 10\n",
    "INPUT_BATCH_SIZE = 5\n",
    "NUM_PROCESSES = 10\n",
    "\n",
    "# final image size\n",
    "# Same size is used in Crop Cats and Dogs\n",
    "X_SIZE = 224\n",
    "Y_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pad == True, maintain aspect ratio and pad images otherwise just rescale\n",
    "def image_resize(image, x_size, y_size, pad):\n",
    "    \n",
    "    if pad:\n",
    "        new_image = np.zeros((y_size, x_size, 3), np.uint8)\n",
    "        new_image[:, 0:x_size] = (0, 255, 0) # (B, G, R) -- pure green padding\n",
    "\n",
    "        w,h,c = image.shape\n",
    "        \n",
    "        if w > h:\n",
    "            scale_factor = x_size/w\n",
    "        else:\n",
    "            scale_factor = y_size/h\n",
    "            \n",
    "        image = cv2.resize(image, (0,0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "        x_offset = int((x_size - image.shape[1])/2)\n",
    "        y_offset = int((y_size - image.shape[0])/2)\n",
    "\n",
    "        new_image[ y_offset:y_offset+image.shape[0], x_offset:x_offset+image.shape[1]] = image\n",
    "\n",
    "        return new_image\n",
    "    \n",
    "    else:\n",
    "        image = cv2.resize(image, (x_size, y_size))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ntZ1AkXZIxY"
   },
   "source": [
    "This section inspired by: [Keras ImageDataGenerator and Data Augmentation](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/) by [Adrian Rosebrock](https://www.pyimagesearch.com/author/adrian/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\program files\\python37\\lib\\site-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VJaCNlDDRz6d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "#from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all masking artifacts from image\n",
    "# very slow and inefficient, could be done better\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def mask_alpha(img):\n",
    "\n",
    "    RED, GREEN, BLUE, ALPHA = (0, 1, 2, 3)\n",
    "\n",
    "    x,y,c = img.shape\n",
    "    alpha_channel = np.zeros([x,y])\n",
    "\n",
    "    for i in range(x):\n",
    "\n",
    "        for j in range(y):\n",
    "\n",
    "            r=img[i][j][RED]\n",
    "            g=img[i][j][GREEN]\n",
    "            b=img[i][j][BLUE]\n",
    "\n",
    "            if (r == 0.0 and g == 0.0 and b == 0.0) or (r == 0.0 and g == 1.0 and b == 0.0):\n",
    "                alpha_channel[i][j] = 0.0\n",
    "            else:\n",
    "                alpha_channel[i][j] = 1.0\n",
    "\n",
    "    # erode mask to get rid of more of the green screen\n",
    "    kernel = np.ones((5,5), np.uint8)  \n",
    "    alpha_channel = cv2.erode(alpha_channel, kernel, iterations=1)\n",
    "    alpha_channel = np.expand_dims(alpha_channel,axis=2)\n",
    "\n",
    "    img = np.concatenate((img, alpha_channel), axis=2)\n",
    "\n",
    "    # crop image using alpha mask\n",
    "    pil_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "    mask = Image.new(\"RGBA\", pil_img.size, (0, 0, 0, 0))\n",
    "    bbox_image = Image.composite(pil_img, mask, pil_img)\n",
    "    bbox = bbox_image.convert(\"RGBa\").getbbox()\n",
    "    pil_img = pil_img.crop(bbox)\n",
    "    img = np.array(pil_img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g2hKZwRc3Nc-",
    "outputId": "332cafe5-37e7-4485-fe5d-3b4d74ffde18"
   },
   "outputs": [],
   "source": [
    "def augmentImages(data, filenames):\n",
    "\n",
    "    # init augmentor\n",
    "    aug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"constant\",\n",
    "        cval = 0)\n",
    "\n",
    "    file_num = 0\n",
    "\n",
    "    # we need to break the loop by hand because the generator loops indefinitely\n",
    "    augmentation_ctr = 0\n",
    "\n",
    "    for images, labels in aug.flow(data, filenames, batch_size=NUM_AUGMENTATIONS):\n",
    "\n",
    "        augmentation_ctr += 1\n",
    "        if augmentation_ctr >= NUM_AUGMENTATIONS:\n",
    "            break\n",
    "\n",
    "        for i in range(images.shape[0]):\n",
    "\n",
    "            img=images[i]\n",
    "            img = mask_alpha(img)\n",
    "\n",
    "            file_num = file_num + 1\n",
    "            filename = labels[i] + '-' + str(file_num) +  '.png'\n",
    "\n",
    "            imageio.imwrite(OUTPUT_PATH + '/' + filename, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BFvAQeGH2u8a",
    "outputId": "e62ba543-cec2-4180-d6ee-573198c826ea"
   },
   "outputs": [],
   "source": [
    "def processBatch(inputFilename):\n",
    "\n",
    "    data = []\n",
    "    filenames = []\n",
    "    \n",
    "    label = inputFilename.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(inputFilename)\n",
    "    image = image_resize(image, X_SIZE, Y_SIZE, True)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # switch the color oder\n",
    "\n",
    "    # output original image as png with mask removed\n",
    "    original_image = np.array(image, dtype=\"float\") / 255.0\n",
    "    original_image = mask_alpha(original_image)\n",
    "\n",
    "    filename, file_extension = os.path.splitext(os.path.basename(inputFilename))\n",
    "    imageio.imwrite(OUTPUT_PATH + '/' + filename + '-original.png', original_image)\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    filenames.append(filename)\n",
    "\n",
    "    # convert the data into a NumPy array, then preprocess it by scaling all pixel intensities to the range [0, 1]\n",
    "    np_data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "    # perform augmentation on batch of images\n",
    "    if len(data) > 0:\n",
    "        augmentImages(np_data, filenames)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Augmenting Images - Elapsed Time: 0.1 Secs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "https://pymotw.com/2/multiprocessing/communication.html\n",
    "    \n",
    "def reader_proc(queue):\n",
    "    ## Read from the queue; this will be spawned as a separate Process\n",
    "    while True:\n",
    "        msg = queue.get()         # Read from the queue and do nothing\n",
    "        if (msg == 'DONE'):\n",
    "            break\n",
    "\n",
    "def writer(filename, queue):\n",
    "    queue.put(filename)             \n",
    "    \n",
    "# The threader thread pulls an worker from the queue and processes it\n",
    "#def reader_proc(queue):\n",
    "#    x = 0\n",
    "#    while True:\n",
    "#        x = x + 1\n",
    "        # gets an worker from the queue\n",
    "        #filename = queue.get()\n",
    "\n",
    "        #if (filename == 'DONE'):\n",
    "        #    break\n",
    "            \n",
    "        # Run the example job with the avail worker in queue (thread)\n",
    "        # processBatch(filename)\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    pqueue = Queue() # writer() writes to pqueue from _this_ process\n",
    "    reader_p = Process(target=reader_proc, args=((pqueue),))\n",
    "    reader_p.daemon = True\n",
    "    reader_p.start()        # Launch reader_proc() as a separate python process\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # augment files in batches\n",
    "    for filename in glob.iglob(INPUT_FILES):\n",
    "        writer(count, pqueue)\n",
    "        # processQueue.put(filename)\n",
    "\n",
    "    #processQueue.put(\"DONE\")\n",
    "\n",
    "    # wait for threads to finish\n",
    "    reader_p.join()\n",
    "\n",
    "    run_time = time.time()-start_time\n",
    "    print('Done Augmenting Images - Elapsed Time: {:.1f}'.format(run_time) + ' Secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section insipred by: [kaggle uploader](https://www.kaggle.com/donkeys/kaggle-uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud Plaform for Kaggle(Beta) does not support /usr/lib modules at this time \n",
    "# Save Output Dataset\n",
    "\n",
    "if isLocalhost == False:\n",
    "\n",
    "    ! python -m pip install --index-url https://test.pypi.org/simple/ --no-deps kaggle_uploader-screamatthewind\n",
    "\n",
    "    import time\n",
    "    import os\n",
    "\n",
    "    from kaggle_uploader import kaggle_uploader \n",
    "\n",
    "    print(\"Saving Images to Kaggle\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # kaggle_secrets are not supported by Google Cloud Platform for Kaggle(Beta) at this time\n",
    "    # from kaggle_secrets import UserSecretsClient\n",
    "    # user_secrets = UserSecretsClient()\n",
    "    # api_secret = user_secrets.get_secret(\"Crop Cats and Cogs YOLOv3\")\n",
    "\n",
    "    kaggle_uploader.resources = []\n",
    "    kaggle_uploader.init_on_kaggle(USER_ID, API_TOKEN)\n",
    "    kaggle_uploader.base_path = OUTPUT_PATH\n",
    "    kaggle_uploader.title = OUTPUT_DATASET_NAME\n",
    "    kaggle_uploader.dataset_id = OUTPUT_DATASET_ID\n",
    "    kaggle_uploader.user_id = USER_ID\n",
    "\n",
    "    for filename in os.listdir(kaggle_uploader.base_path):\n",
    "        print(filename)\n",
    "        kaggle_uploader.add_resource(filename, filename)\n",
    "\n",
    "    kaggle_uploader.update(\"new version\")\n",
    "\n",
    "    run_time = time.time()-start_time\n",
    "    print('Done Saving Images - Total Time: {:.1f}'.format(run_time) + ' Secs')\n",
    "\n",
    "    # If you get an error during update, it is typically because of an invalid api key, bad username, \n",
    "    # or the dataset does not exist.  This code does not create datasets.  It updates existing ones\n",
    "\n",
    "else:\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
