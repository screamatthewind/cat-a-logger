{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# from subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_FILES = '/kaggle/input/cropped-cats-and-dogs'\n\nOUTPUT_DATASET_ID = 'augmented-cats-and-dogs'\nOUTPUT_DATASET_NAME = 'Augmented Cats and Dogs'\nOUTPUT_PATH = './output'\n\n# kaggle_secrets not supported by Google Cloud Platform for Kaggle(Beta) at this time\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n#API_TOKEN = user_secrets.get_secret(\"Crop Cats and Cogs YOLOv3\")\n\nUSER_ID = 'KAGGLE-USERNAME' # use your own username\nAPI_TOKEN = 'KAGGLE-API-TOKEN' # use your own kaggle api key\n\nBATCH_SIZE = 16 \nITERATIONS = 10\n\n# final image size\n# Same size is used in Crop Cats and Dogs\nX_SIZE = 224\nY_SIZE = 224","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nif not os.path.exists(OUTPUT_PATH):\n    os.makedirs(OUTPUT_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if pad == True, maintain aspect ratio and pad images otherwise just rescale\ndef image_resize(image, x_size, y_size, pad):\n    \n    if pad:\n        new_image = np.zeros((y_size, x_size, 3), np.uint8)\n        new_image[:, 0:x_size] = (0, 255, 0) # (B, G, R) -- pure green padding\n\n        w,h,c = image.shape\n        \n        if w > h:\n            scale_factor = x_size/w\n        else:\n            scale_factor = y_size/h\n            \n        image = cv2.resize(image, (0,0), fx=scale_factor, fy=scale_factor)\n\n        x_offset = int((x_size - image.shape[1])/2)\n        y_offset = int((y_size - image.shape[0])/2)\n\n        new_image[ y_offset:y_offset+image.shape[0], x_offset:x_offset+image.shape[1]] = image\n\n        return new_image\n    \n    else:\n        image = cv2.resize(image, (x_size, y_size))\n        return image","execution_count":null,"outputs":[]},{"metadata":{"id":"8ntZ1AkXZIxY"},"cell_type":"markdown","source":"This section inspired by: [Keras ImageDataGenerator and Data Augmentation](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/) by [Adrian Rosebrock](https://www.pyimagesearch.com/author/adrian/)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"id":"VJaCNlDDRz6d","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom imutils import paths\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove all masking artifacts from image\n# very slow and inefficient, could be done better\nfrom PIL import Image, ImageDraw\n\ndef mask_alpha(img):\n\n    RED, GREEN, BLUE, ALPHA = (0, 1, 2, 3)\n\n    x,y,c = img.shape\n    alpha_channel = np.zeros([x,y])\n\n    for i in range(x):\n\n        for j in range(y):\n\n            r=img[i][j][RED]\n            g=img[i][j][GREEN]\n            b=img[i][j][BLUE]\n\n            if (r == 0.0 and g == 0.0 and b == 0.0) or (r == 0.0 and g == 1.0 and b == 0.0):\n                alpha_channel[i][j] = 0.0\n            else:\n                alpha_channel[i][j] = 1.0\n\n    # erode mask to get rid of more of the green screen\n    kernel = np.ones((5,5), np.uint8)  \n    alpha_channel = cv2.erode(alpha_channel, kernel, iterations=1)\n    alpha_channel = np.expand_dims(alpha_channel,axis=2)\n\n    img = np.concatenate((img, alpha_channel), axis=2)\n\n    # crop image using alpha mask\n    pil_img = Image.fromarray((img * 255).astype(np.uint8))\n    mask = Image.new(\"RGBA\", pil_img.size, (0, 0, 0, 0))\n    bbox_image = Image.composite(pil_img, mask, pil_img)\n    bbox = bbox_image.convert(\"RGBa\").getbbox()\n    pil_img = pil_img.crop(bbox)\n    img = np.array(pil_img)\n\n    return img","execution_count":null,"outputs":[]},{"metadata":{"id":"BFvAQeGH2u8a","outputId":"e62ba543-cec2-4180-d6ee-573198c826ea","trusted":true},"cell_type":"code","source":"# grab the list of images in our dataset directory, then initialize\n# the list of data (i.e., images) and class images\n\nprint(\"loading images from:\", INPUT_FILES)\n\ndata = []\nfile_names = []\nimagePaths = list(paths.list_images(INPUT_FILES))\n\n# loop over the image paths\nfor imagePath in imagePaths:\n    \n    label = imagePath.split(os.path.sep)[-2]\n    image = cv2.imread(imagePath)\n    image = image_resize(image, X_SIZE, Y_SIZE, True)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # switch the color oder\n\n    # output original image as png with mask removed\n    original_image = np.array(image, dtype=\"float\") / 255.0\n    original_image = mask_alpha(original_image)\n    \n    file_name, file_extension = os.path.splitext(os.path.basename(imagePath))\n    imageio.imwrite(OUTPUT_PATH + '/' + file_name + '-original.png', original_image)\n\n    # update the data and labels lists, respectively\n    data.append(image)\n    file_names.append(file_name)\n    print(file_name)","execution_count":null,"outputs":[]},{"metadata":{"id":"eJR1ZMFN3FxL","trusted":true},"cell_type":"code","source":"# convert the data into a NumPy array, then preprocess it by scaling\n# all pixel intensities to the range [0, 1]\ndata = np.array(data, dtype=\"float\") / 255.0\n\n# encode the labels (which are currently strings) as integers and then\n# one-hot encode them\nle = LabelEncoder()\nlabels = le.fit_transform(file_names)\nprint(labels)\n#labels = to_categorical(labels)\n#print(labels[0])\n\n# partition the data into training and testing splits using 75% of\n# the data for training and the remaining 25% for testing\n(trainX, testX, trainY, testY) = train_test_split(data, file_names, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(file_names[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"g2hKZwRc3Nc-","outputId":"332cafe5-37e7-4485-fe5d-3b4d74ffde18","trusted":true},"cell_type":"code","source":"aug = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"constant\",\n    cval = 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"NK28Fn1pPbun","outputId":"45c030ab-5e26-4a11-d5ce-b97273bd89f4","trusted":true},"cell_type":"code","source":"test_gen=aug.flow(trainX, trainY, batch_size=BATCH_SIZE)\nimages,labels=next(test_gen)  # returns the next batch of images and labels \nfor i in range(images.shape[0]):\n    print(labels[i])\n    img=images[i]   # this is the first image  batch[0][1] would be the next image\n    plt.imshow(img)   # shows the first image\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Processing Images\")\nstart_time = time.time()\n\nfile_num = 0\n\n# we need to break the loop by hand because the generator loops indefinitely\nfor e in range(ITERATIONS):\n    \n    batches = 0\n\n    # aug_gen=aug.flow(trainX, trainY, batch_size=BATCH_SIZE)\n    #images,labels=next(aug_gen)  # returns the next batch of images and labels \n    # for i in range(images.shape[0]):\n\n    for images, labels in aug.flow(trainX, trainY, batch_size=BATCH_SIZE):\n        \n        batches += 1\n        if batches >= len(trainX) / BATCH_SIZE:\n            break\n\n        for i in range(images.shape[0]):\n        # for img in images:\n            img=images[i]\n            img = mask_alpha(img)\n             \n            file_num = file_num + 1\n            imageio.imwrite(OUTPUT_PATH + '/' + labels[i] + '-' + str(file_num) +  '.png', img)\n\n            # plt.imshow(img)   \n            # plt.show()        \n\nrun_time = time.time()-start_time\nprint('Done Processing Images - Total Time: {:.1f}'.format(run_time) + ' Secs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls $OUTPUT_PATH","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This section insipred by: [kaggle uploader[](http://)](https://www.kaggle.com/donkeys/kaggle-uploader)"},{"metadata":{"trusted":true},"cell_type":"code","source":"! python -m pip install --index-url https://test.pypi.org/simple/ --no-deps kaggle_uploader-screamatthewind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\n\nfrom kaggle_uploader import kaggle_uploader\n\nprint(\"Saving Images\")\nstart_time = time.time()\n\n# kaggle_secrets are not supported by Google Cloud Platform for Kaggle(Beta) at this time\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# api_secret = user_secrets.get_secret(\"Crop Cats and Cogs YOLOv3\")\n\nkaggle_uploader.resources = []\nkaggle_uploader.init_on_kaggle(USER_ID, API_TOKEN)\nkaggle_uploader.base_path = OUTPUT_PATH\nkaggle_uploader.title = OUTPUT_DATASET_NAME\nkaggle_uploader.dataset_id = OUTPUT_DATASET_ID\nkaggle_uploader.user_id = USER_ID\n\nfor filename in os.listdir(kaggle_uploader.base_path):\n    kaggle_uploader.add_resource(filename, filename)\n    \nkaggle_uploader.update(\"new version\")\n\nrun_time = time.time()-start_time\nprint('Done Saving Images - Total Time: {:.1f}'.format(run_time) + ' Secs')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}